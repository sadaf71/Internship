{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c6ad5b",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url =\n",
    "https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50056b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d4c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b32a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d6e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting Name Via X path\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Artist Name Via Xpath\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "\n",
    "# Extracting Upload date Via Xpath\n",
    "try:\n",
    "    upload_date=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA') \n",
    "\n",
    "# Extracting Views via Xpath\n",
    "try:\n",
    "    views=driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad2af4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wiki=pd.DataFrame({'Rank':Rank,'Video Name':Name,'Uploader':Artist,'Views (in Billons)':Views,'Upload Date':Upload_date})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "042c36fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (in Billons)</th>\n",
       "      <th>Upload Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>13.29</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.25</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>6.78</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>6.38</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.07</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>6.01</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>5.53</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>5.47</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>5.02</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.96</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>4.88</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.56</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>4.43</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.04</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.93</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[39]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.86</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.86</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>3.76</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[43]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.70</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.67</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.65</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.58</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.54</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.53</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Faded\"[49]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.51</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.50</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>3.45</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.45</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    7.                          \"Wheels on the Bus\"[26]   \n",
       "7    8.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                             \"Counting Stars\"[39]   \n",
       "16  17.                                       \"Roar\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "19  20.                                      \"Sorry\"[43]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[44]   \n",
       "21  22.                          \"Thinking Out Loud\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[47]   \n",
       "24  25.                                    \"Perfect\"[48]   \n",
       "25  26.                                      \"Faded\"[49]   \n",
       "26  27.                                 \"Let Her Go\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                    \"Lean On\"[52]   \n",
       "29  30.                                   \"Bailando\"[53]   \n",
       "\n",
       "                                             Uploader Views (in Billons)  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories              13.29   \n",
       "1                                          Luis Fonsi               8.25   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs               6.78   \n",
       "3                          Cocomelon - Nursery Rhymes               6.38   \n",
       "4                                          Ed Sheeran               6.07   \n",
       "5                                         Wiz Khalifa               6.01   \n",
       "6                          Cocomelon - Nursery Rhymes               5.53   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs               5.47   \n",
       "8                                         Mark Ronson               5.02   \n",
       "9                                         Miroshka TV               4.96   \n",
       "10                                        officialpsy               4.88   \n",
       "11                                         Get Movies               4.56   \n",
       "12                                      Ultra Records               4.43   \n",
       "13                                         Crazy Frog               4.04   \n",
       "14                                           Maroon 5               3.93   \n",
       "15                                        OneRepublic               3.86   \n",
       "16                                         Katy Perry               3.86   \n",
       "17                         Cocomelon - Nursery Rhymes               3.76   \n",
       "18                                            Shakira               3.71   \n",
       "19                                      Justin Bieber               3.70   \n",
       "20                                       Jingle Toons               3.67   \n",
       "21                                         Ed Sheeran               3.65   \n",
       "22                                         Katy Perry               3.58   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs               3.54   \n",
       "24                                         Ed Sheeran               3.53   \n",
       "25                                        Alan Walker               3.51   \n",
       "26                                          Passenger               3.50   \n",
       "27                                           Maroon 5               3.47   \n",
       "28                               Major Lazer Official               3.45   \n",
       "29                                   Enrique Iglesias               3.45   \n",
       "\n",
       "          Upload Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6        May 24, 2018  \n",
       "7       March 6, 2014  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15       May 31, 2013  \n",
       "16  September 5, 2013  \n",
       "17      June 25, 2018  \n",
       "18       June 4, 2010  \n",
       "19   October 22, 2015  \n",
       "20      June 14, 2018  \n",
       "21    October 7, 2014  \n",
       "22  February 20, 2014  \n",
       "23   January 26, 2018  \n",
       "24   November 9, 2017  \n",
       "25   December 3, 2015  \n",
       "26      July 25, 2012  \n",
       "27       May 31, 2018  \n",
       "28     March 22, 2015  \n",
       "29     April 11, 2014  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7c817",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details: \n",
    "A) Match title (I.e. 1 ODI) \n",
    "B) Series \n",
    "C) Place \n",
    "D) Date \n",
    "E) Time \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99e8c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.bcci.tv/.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a91e6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "try:\n",
    "    fixtures.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2f29344",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL= []\n",
    "link=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b75da322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36db2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "288bca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentException",
     "evalue": "Message: invalid argument: 'url' must be a string\n  (Session info: chrome=116.0.5845.180)\nStacktrace:\n\tGetHandleVerifier [0x00007FF78C3152A2+57122]\n\t(No symbol) [0x00007FF78C28EA92]\n\t(No symbol) [0x00007FF78C15E3AB]\n\t(No symbol) [0x00007FF78C1CEFCA]\n\t(No symbol) [0x00007FF78C1B6FDA]\n\t(No symbol) [0x00007FF78C1CEB82]\n\t(No symbol) [0x00007FF78C1B6DB3]\n\t(No symbol) [0x00007FF78C18D2B1]\n\t(No symbol) [0x00007FF78C18E494]\n\tGetHandleVerifier [0x00007FF78C5BEF82+2849794]\n\tGetHandleVerifier [0x00007FF78C611D24+3189156]\n\tGetHandleVerifier [0x00007FF78C60ACAF+3160367]\n\tGetHandleVerifier [0x00007FF78C3A6D06+653702]\n\t(No symbol) [0x00007FF78C29A208]\n\t(No symbol) [0x00007FF78C2962C4]\n\t(No symbol) [0x00007FF78C2963F6]\n\t(No symbol) [0x00007FF78C2867A3]\n\tBaseThreadInitThunk [0x00007FF9AB787614+20]\n\tRtlUserThreadStart [0x00007FF9ACB426B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6172\\816899716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Scraping Match title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;34m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInvalidArgumentException\u001b[0m: Message: invalid argument: 'url' must be a string\n  (Session info: chrome=116.0.5845.180)\nStacktrace:\n\tGetHandleVerifier [0x00007FF78C3152A2+57122]\n\t(No symbol) [0x00007FF78C28EA92]\n\t(No symbol) [0x00007FF78C15E3AB]\n\t(No symbol) [0x00007FF78C1CEFCA]\n\t(No symbol) [0x00007FF78C1B6FDA]\n\t(No symbol) [0x00007FF78C1CEB82]\n\t(No symbol) [0x00007FF78C1B6DB3]\n\t(No symbol) [0x00007FF78C18D2B1]\n\t(No symbol) [0x00007FF78C18E494]\n\tGetHandleVerifier [0x00007FF78C5BEF82+2849794]\n\tGetHandleVerifier [0x00007FF78C611D24+3189156]\n\tGetHandleVerifier [0x00007FF78C60ACAF+3160367]\n\tGetHandleVerifier [0x00007FF78C3A6D06+653702]\n\t(No symbol) [0x00007FF78C29A208]\n\t(No symbol) [0x00007FF78C2962C4]\n\t(No symbol) [0x00007FF78C2963F6]\n\t(No symbol) [0x00007FF78C2867A3]\n\tBaseThreadInitThunk [0x00007FF9AB787614+20]\n\tRtlUserThreadStart [0x00007FF9ACB426B1+33]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    # Scraping Match title\n",
    "    try:\n",
    "        title=driver.find_elements(By.XPATH,'//div[@class=\"tournament--name ng-binding ng-scope\"]')\n",
    "        Title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Title.append('NA')\n",
    "        \n",
    "    # Scraping Series Via Xpath\n",
    "    try:\n",
    "        series=driver.find_element(By.XPATH,'//li[@class=\"ng-scope\"]/span[1]')\n",
    "        Series.append(series.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('NA')\n",
    "        \n",
    "    # Scraping venue Via Xpath\n",
    "    try:\n",
    "        place=driver.find_element(By.XPATH,'//span[@class=\"matGround ng-binding\"]')\n",
    "        Place.append(place.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append('NA')\n",
    "        \n",
    "    # Scraping date Via Xpath\n",
    "    try:\n",
    "        date=driver.find_element(By.XPATH,'//div[@class=\"matchDate alignC ng-binding ng-scope\"]')\n",
    "        Date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('NA')\n",
    "     \n",
    "        # Scraping Time Via Xpath\n",
    "    try:\n",
    "        time=driver.find_element(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "        Time.append(time.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append('NA')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ed8a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328fb4f3",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A)\n",
    "Rank \n",
    "B) State \n",
    "C) GSDP(18-19)- at current prices \n",
    "D) GSDP(19-20)- at current prices \n",
    "E) Share(18-19) \n",
    "F) GDP($ billion) \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74cf5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed3deff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank =[]\n",
    "State =[]\n",
    "GDSP_19_20=[]\n",
    "GDSP_18_19 =[]\n",
    "Share =[]\n",
    "GDP =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "382ebd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "India=driver.find_element(By.XPATH,'//div[@class=\"dropdown\"][2]/div/a[3]')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))\n",
    "    \n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a186d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Indian State GDP\n",
    "state = driver.find_element(By.XPATH,'//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')\n",
    "try:\n",
    "    state.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a3ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rank=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting state name via Xpath\n",
    "try:\n",
    "    state=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20 via Xpath\n",
    "try:\n",
    "    gdsp_19_20=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gdsp_19_20:\n",
    "        GDSP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19 via Xpath\n",
    "try:\n",
    "    gdsp_18_19=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdsp_18_19:\n",
    "        GDSP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_18_19.append('NA')\n",
    "    \n",
    "# Extracting share in billons via Xpath\n",
    "try:\n",
    "    share=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "\n",
    "# Extracting GDP via Xpath\n",
    "try:\n",
    "    gdp=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4dc26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=pd.DataFrame({'Rank':Rank,'State':State,'GDSP 19-20':GDSP_19_20,'GDSP 18-19':GDSP_18_19,\n",
    "                            'Share':Share,'GDP (in Billions)':GDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6eb58c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP 19-20</th>\n",
       "      <th>GDSP 18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GDSP 19-20 GDSP 18-19   Share  \\\n",
       "0     1                Maharashtra          -  2,632,792  13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%   \n",
       "3     4                    Gujarat          -  1,502,899   7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127   7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898   5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586   4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957   4.57%   \n",
       "8     9                  Telangana    969,604    861,031   4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592   4.29%   \n",
       "10   11                     Kerala          -    781,653   4.14%   \n",
       "11   12                      Delhi    856,112    774,870   4.10%   \n",
       "12   13                    Haryana    831,610    734,163   3.89%   \n",
       "13   14                      Bihar    611,804    530,363   2.81%   \n",
       "14   15                     Punjab    574,760    526,376   2.79%   \n",
       "15   16                     Odisha    521,275    487,805   2.58%   \n",
       "16   17                      Assam          -    315,881   1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063   1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204   1.57%   \n",
       "19   20                Uttarakhand          -    245,895   1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956   0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845   0.81%   \n",
       "22   23                        Goa     80,449     73,170   0.39%   \n",
       "23   24                    Tripura     55,984     49,845   0.26%   \n",
       "24   25                 Chandigarh          -     42,114   0.22%   \n",
       "25   26                 Puducherry     38,253     34,433   0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481   0.18%   \n",
       "27   28                     Sikkim     32,496     28,723   0.15%   \n",
       "28   29                    Manipur     31,790     27,870   0.15%   \n",
       "29   30                   Nagaland          -     27,283   0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603   0.13%   \n",
       "31   32                    Mizoram     26,503     22,287   0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -       -   \n",
       "\n",
       "   GDP (in Billions)  \n",
       "0            399.921  \n",
       "1            247.629  \n",
       "2            240.726  \n",
       "3            228.290  \n",
       "4            226.806  \n",
       "5            165.556  \n",
       "6            143.179  \n",
       "7            131.083  \n",
       "8            130.791  \n",
       "9            122.977  \n",
       "10           118.733  \n",
       "11           117.703  \n",
       "12           111.519  \n",
       "13            80.562  \n",
       "14            79.957  \n",
       "15            74.098  \n",
       "16            47.982  \n",
       "17            46.187  \n",
       "18            45.145  \n",
       "19            37.351  \n",
       "20            23.690  \n",
       "21            23.369  \n",
       "22            11.115  \n",
       "23             7.571  \n",
       "24             6.397  \n",
       "25             5.230  \n",
       "26             5.086  \n",
       "27             4.363  \n",
       "28             4.233  \n",
       "29             4.144  \n",
       "30             3.737  \n",
       "31             3.385  \n",
       "32                 -  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb55bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f789706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5788ab86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg=requests.get('https://github.com/')\n",
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0f66992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on trending option\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7afae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Description=[]\n",
    "Count =[]\n",
    "Language =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4390a853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL= []\n",
    "link=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))\n",
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46d2f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    title=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a3f32e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [07:21<00:00, 17.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    # Scraping Description\n",
    "    try:\n",
    "        description=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        Description.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NA')\n",
    "    \n",
    "    # Scraping Contributor count\n",
    "    try:\n",
    "        count=driver.find_element(By.XPATH,\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]\")\n",
    "        Count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('NA')\n",
    "    \n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        lang=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[2]/div[2]/div/div[6]/div/h2\")\n",
    "        if lang:\n",
    "            for j in lang:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        Language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca835dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Github=pd.DataFrame({'Title':Title,'Description':Description,\n",
    "                'Contributors_count':Count,'Language_used':Language})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c667a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>godotengine / godot</td>\n",
       "      <td>Godot Engine – Multi-platform 2D and 3D game e...</td>\n",
       "      <td>Contributors\\n2,205</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coqui-ai / TTS</td>\n",
       "      <td>🐸💬 - a deep learning toolkit for Text-to-Speec...</td>\n",
       "      <td>Contributors\\n128</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>isocpp / CppCoreGuidelines</td>\n",
       "      <td>The C++ Core Guidelines are a set of tried-and...</td>\n",
       "      <td>Contributors\\n325</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MonoGame / MonoGame</td>\n",
       "      <td>One framework for creating powerful cross-plat...</td>\n",
       "      <td>Contributors\\n349</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aiwaves-cn / agents</td>\n",
       "      <td>An Open-source Framework for Autonomous Langua...</td>\n",
       "      <td>Contributors\\n13</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zhile-io / pandora</td>\n",
       "      <td>潘多拉，一个让你呼吸顺畅的ChatGPT。Pandora, a ChatGPT client...</td>\n",
       "      <td>Contributors\\n7</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>badlogic / heissepreise</td>\n",
       "      <td>Jo eh.</td>\n",
       "      <td>Contributors\\n12</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lodash / lodash</td>\n",
       "      <td>A modern JavaScript utility library delivering...</td>\n",
       "      <td>Contributors\\n286</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Klipper3d / klipper</td>\n",
       "      <td>Klipper is a 3d-printer firmware</td>\n",
       "      <td>Contributors\\n383</td>\n",
       "      <td>[Contributors\\n383]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stride3d / stride</td>\n",
       "      <td>Stride Game Engine (formerly Xenko)</td>\n",
       "      <td>Contributors\\n98</td>\n",
       "      <td>[Contributors\\n98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nuejs / nuejs</td>\n",
       "      <td>Build user interfaces with 10x less code. Alte...</td>\n",
       "      <td>Contributors\\n10</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>langchain-ai / langchain-nextjs-template</td>\n",
       "      <td>LangChain + Next.js starter template</td>\n",
       "      <td>NA</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>commaai / openpilot</td>\n",
       "      <td>openpilot is an open source driver assistance ...</td>\n",
       "      <td>Contributors\\n500</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>facebookresearch / nougat</td>\n",
       "      <td>Implementation of Nougat Neural Optical Unders...</td>\n",
       "      <td>Contributors\\n11</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KenneyNL / Starter-Kit-3D-Platformer</td>\n",
       "      <td>Godot</td>\n",
       "      <td>Contributors\\n3</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>godotengine / godot-docs</td>\n",
       "      <td>Godot Engine official documentation</td>\n",
       "      <td>Contributors\\n1,168</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AUTOMATIC1111 / stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>Contributors\\n487</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>yoheinakajima / instagraph</td>\n",
       "      <td>Converts text input or URL into knowledge grap...</td>\n",
       "      <td>Contributors\\n14</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>godotengine / godot-demo-projects</td>\n",
       "      <td>Demonstration and Template Projects</td>\n",
       "      <td>Contributors\\n148</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>guidance-ai / guidance</td>\n",
       "      <td>A guidance language for controlling large lang...</td>\n",
       "      <td>Contributors\\n37</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FlaxEngine / FlaxEngine</td>\n",
       "      <td>Flax Engine – multi-platform 3D game engine</td>\n",
       "      <td>Contributors\\n52</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ripienaar / free-for-dev</td>\n",
       "      <td>A list of SaaS, PaaS and IaaS offerings that h...</td>\n",
       "      <td>Contributors\\n1,470</td>\n",
       "      <td>[NA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fishaudio / Bert-VITS2</td>\n",
       "      <td>vits2 backbone with bert</td>\n",
       "      <td>Contributors\\n9</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>Contributors\\n1,000</td>\n",
       "      <td>[Contributors\\n1,000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>89luca89 / distrobox</td>\n",
       "      <td>Use any linux distribution inside your termina...</td>\n",
       "      <td>Contributors\\n106</td>\n",
       "      <td>[Languages]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0                        godotengine / godot   \n",
       "1                             coqui-ai / TTS   \n",
       "2                 isocpp / CppCoreGuidelines   \n",
       "3                        MonoGame / MonoGame   \n",
       "4                        aiwaves-cn / agents   \n",
       "5                         zhile-io / pandora   \n",
       "6                    badlogic / heissepreise   \n",
       "7                            lodash / lodash   \n",
       "8                        Klipper3d / klipper   \n",
       "9                          stride3d / stride   \n",
       "10                             nuejs / nuejs   \n",
       "11  langchain-ai / langchain-nextjs-template   \n",
       "12                       commaai / openpilot   \n",
       "13                 facebookresearch / nougat   \n",
       "14      KenneyNL / Starter-Kit-3D-Platformer   \n",
       "15                  godotengine / godot-docs   \n",
       "16    AUTOMATIC1111 / stable-diffusion-webui   \n",
       "17                yoheinakajima / instagraph   \n",
       "18         godotengine / godot-demo-projects   \n",
       "19                    guidance-ai / guidance   \n",
       "20                   FlaxEngine / FlaxEngine   \n",
       "21                  ripienaar / free-for-dev   \n",
       "22                    fishaudio / Bert-VITS2   \n",
       "23                    TheAlgorithms / Python   \n",
       "24                      89luca89 / distrobox   \n",
       "\n",
       "                                          Description   Contributors_count  \\\n",
       "0   Godot Engine – Multi-platform 2D and 3D game e...  Contributors\\n2,205   \n",
       "1   🐸💬 - a deep learning toolkit for Text-to-Speec...    Contributors\\n128   \n",
       "2   The C++ Core Guidelines are a set of tried-and...    Contributors\\n325   \n",
       "3   One framework for creating powerful cross-plat...    Contributors\\n349   \n",
       "4   An Open-source Framework for Autonomous Langua...     Contributors\\n13   \n",
       "5   潘多拉，一个让你呼吸顺畅的ChatGPT。Pandora, a ChatGPT client...      Contributors\\n7   \n",
       "6                                              Jo eh.     Contributors\\n12   \n",
       "7   A modern JavaScript utility library delivering...    Contributors\\n286   \n",
       "8                    Klipper is a 3d-printer firmware    Contributors\\n383   \n",
       "9                 Stride Game Engine (formerly Xenko)     Contributors\\n98   \n",
       "10  Build user interfaces with 10x less code. Alte...     Contributors\\n10   \n",
       "11               LangChain + Next.js starter template                   NA   \n",
       "12  openpilot is an open source driver assistance ...    Contributors\\n500   \n",
       "13  Implementation of Nougat Neural Optical Unders...     Contributors\\n11   \n",
       "14                                              Godot      Contributors\\n3   \n",
       "15                Godot Engine official documentation  Contributors\\n1,168   \n",
       "16                            Stable Diffusion web UI    Contributors\\n487   \n",
       "17  Converts text input or URL into knowledge grap...     Contributors\\n14   \n",
       "18                Demonstration and Template Projects    Contributors\\n148   \n",
       "19  A guidance language for controlling large lang...     Contributors\\n37   \n",
       "20        Flax Engine – multi-platform 3D game engine     Contributors\\n52   \n",
       "21  A list of SaaS, PaaS and IaaS offerings that h...  Contributors\\n1,470   \n",
       "22                           vits2 backbone with bert      Contributors\\n9   \n",
       "23               All Algorithms implemented in Python  Contributors\\n1,000   \n",
       "24  Use any linux distribution inside your termina...    Contributors\\n106   \n",
       "\n",
       "            Language_used  \n",
       "0             [Languages]  \n",
       "1             [Languages]  \n",
       "2             [Languages]  \n",
       "3             [Languages]  \n",
       "4                    [NA]  \n",
       "5             [Languages]  \n",
       "6             [Languages]  \n",
       "7             [Languages]  \n",
       "8     [Contributors\\n383]  \n",
       "9      [Contributors\\n98]  \n",
       "10                   [NA]  \n",
       "11                   [NA]  \n",
       "12                   [NA]  \n",
       "13                   [NA]  \n",
       "14                   [NA]  \n",
       "15                   [NA]  \n",
       "16            [Languages]  \n",
       "17                   [NA]  \n",
       "18            [Languages]  \n",
       "19            [Languages]  \n",
       "20                   [NA]  \n",
       "21                   [NA]  \n",
       "22            [Languages]  \n",
       "23  [Contributors\\n1,000]  \n",
       "24            [Languages]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cffc5ed",
   "metadata": {},
   "source": [
    "# Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e80d2afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2578025",
   "metadata": {},
   "outputs": [],
   "source": [
    "Song =[]\n",
    "Artist =[]\n",
    "Last_Week_rank=[]\n",
    "Peak_rank =[]\n",
    "Weeks =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3306065",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_100=driver.find_element(By.XPATH,'//span[@class=\"c-label  \"][1]/a')\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "028c5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    song=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "    for i in song:\n",
    "        Song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song.append('NA')\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[4]')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('NA')\n",
    "    \n",
    "# Scraping Song last week rank\n",
    "try:\n",
    "    last_rank=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[4]')\n",
    "    for i in last_rank:\n",
    "        Last_Week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_Week_rank.append('NA')\n",
    "\n",
    "# Scraping Song peak rank\n",
    "try:\n",
    "    peak=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[5]')\n",
    "    for i in peak:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('NA')\n",
    "\n",
    "# Scraping Song weeks\n",
    "try:\n",
    "    weeks=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[6]')\n",
    "    for i in weeks:\n",
    "        Weeks.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks.append('NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0436d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Weeks_on_chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sittin' On Top Of The World</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TQM</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>34</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Amargura</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song_Name Artist_Name Last_week_rank Peak Weeks_on_chart\n",
       "0                       Vampire           9              9    1             11\n",
       "1            Paint The Town Red           1              1    1              6\n",
       "2         I Remember Everything           2              2    1              3\n",
       "3                      Fast Car           3              3    2             25\n",
       "4                  Cruel Summer           4              4    3             19\n",
       "..                          ...         ...            ...  ...            ...\n",
       "95                      Lagunas           -              -   77              9\n",
       "96  Sittin' On Top Of The World          86             86   80              3\n",
       "97                      Rubicon          95             95   63             11\n",
       "98                          TQM          89             89   34             17\n",
       "99                     Amargura          91             91   85              5\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billboard=pd.DataFrame({'Song_Name':Song,\n",
    "                'Artist_Name':Artist,\n",
    "                'Last_week_rank':Last_Week_rank,\n",
    "                'Peak':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks})\n",
    "Billboard\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed415a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Song),len(Artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad00c9",
   "metadata": {},
   "source": [
    "# Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1239d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22e1cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27d41e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    book=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('NA')\n",
    "    \n",
    "# Scraping Book author's via Xpath\n",
    "try:\n",
    "    author=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold via Xpath\n",
    "try:\n",
    "    sold=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher via xPath\n",
    "try:\n",
    "    publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79585042",
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d5f76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c299820",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/ You \n",
    "have to find the following details: \n",
    "A) Name \n",
    "B) Year span \n",
    "C) Genre \n",
    "D) Run time \n",
    "E) Ratings \n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5b1c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2c0702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year_Span=[]\n",
    "Genre=[]\n",
    "Run_Time=[]\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "200d8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "\n",
    "# Scraping Year span via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "    for i in year:\n",
    "        Year_Span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_Span.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "# Scraping RunTime via Xpath\n",
    "try:\n",
    "    runtime=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "    for i in runtime:\n",
    "        Run_Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_Time.append('NA')\n",
    "\n",
    "# Scraping Ratings via Xpath\n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "\n",
    "# Scraping Votes via Xpath\n",
    "try:\n",
    "    votes=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32de5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_TV=pd.DataFrame({\"Name\":Name,\n",
    "                \"Year Span\":Year_Span,\n",
    "                \"Genre\":Genre,\n",
    "                \"Run Time\":Run_Time,\n",
    "                \"Ratings\":Ratings,\n",
    "                \"Votes\":Votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3487e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,204,981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,276,363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,046,219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>307,478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>266,181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,204,981  \n",
       "1    51 min     8.7  1,276,363  \n",
       "2    44 min     8.1  1,046,219  \n",
       "3    60 min     7.5    307,478  \n",
       "4    43 min     7.6    266,557  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,746  \n",
       "96   50 min     7.8     64,810  \n",
       "97   42 min     8.1    211,105  \n",
       "98   45 min       7     43,918  \n",
       "99  572 min     8.6    266,181  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7812a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ab08b25",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "348b21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4795a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=driver.find_element(By.XPATH,'//a[@href=\"/datasets\"][1]')\n",
    "dataset.click()\n",
    "time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67b46d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset =[]\n",
    "Data_Type =[]\n",
    "Task =[]\n",
    "Attribute_Type =[]\n",
    "No_of_Instances =[]\n",
    "No_of_Attribute =[]\n",
    "Year =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cde81f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "try:\n",
    "    dataset=driver.find_elements(By.XPATH,'//h2[@class=\"truncate text-primary\"]/a')\n",
    "    for i in tqdm(dataset):\n",
    "        Dataset.append(i.text)\n",
    "        time.sleep(0.15)\n",
    "except NoSuchElementException:\n",
    "    Dataset.append('NA')\n",
    "    \n",
    "# Scraping Data Type via Xpath\n",
    "try:\n",
    "    Type=driver.find_elements(By.XPATH,'//div[@class=\"grid grid-cols-8 gap-4 md:grid-cols-12\"]/div/p[1]')\n",
    "    for i in Type[1:]:\n",
    "        Data_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Data_Type.append('NA')\n",
    "    \n",
    "# Scraping Task via Xpath\n",
    "try:\n",
    "    task=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type via Xpath\n",
    "try:\n",
    "    attribute_Type=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')\n",
    "    for i in attribute_Type[1:]:\n",
    "        Attribute_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute_Type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances via Xpath\n",
    "try:\n",
    "    no_of_Instances=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')\n",
    "    for i in no_of_Instances[1:]:\n",
    "        No_of_Instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instances.append('NA')\n",
    "\n",
    "# Scraping No_of_Attribute via Xpath\n",
    "try:\n",
    "    no_of_Attribute=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')\n",
    "\n",
    "    for i in no_of_Attribute[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('NA')\n",
    "    \n",
    "# Scraping Year via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/h2')\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3b0f153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5, 0, 0, 0, 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset),len(Data_Type),len(Task),len(Attribute_Type),len(No_of_Instances),len(Year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbafe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
